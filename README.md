# ğŸ¤ Multilingual Voice Assistant

A powerful **AI Voice Assistant** capable of:

âœ… Recording voice input
âœ… Transcribing speech using **Whisper**
âœ… Translating text into multiple languages
âœ… Generating voice responses
âœ… Running locally or inside a DevContainer
âœ… Supporting multiple audio formats (`wav`, `mp3`)

This repository contains all scripts, audio samples, utilities, and configuration files required to run the assistant.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ .devcontainer/                # VS Code dev-container setup
â”œâ”€â”€ MultilingualVoiceAssistant/   # Main Voice Assistant module
â”œâ”€â”€ utils/                        # Helper utilities (audio processing, etc.)
â”‚
â”œâ”€â”€ MultilingualVoiceAssistant.zip # Compressed source (backup/export)
â”œâ”€â”€ app.py                        # Main Streamlit / GUI App
â”œâ”€â”€ voice_assistant.py            # Core assistant logic
â”œâ”€â”€ whis.py                       # Whisper STT module
â”œâ”€â”€ warn.py                       # Warning/notification system
â”œâ”€â”€ test.py                       # Test script
â”œâ”€â”€ input.wav                     # Sample input audio
â”œâ”€â”€ logo.png                      # Project logo for UI
â”œâ”€â”€ temp.mp3                      # Temporary audio output
â”œâ”€â”€ ta_test.mp3                   # Test audio file
â”œâ”€â”€ requirements.txt              # Dependencies
```

---

# ğŸš€ Features

### ğŸ—£ï¸ Speech-to-Text (STT)

* Uses **OpenAI Whisper** (local or API-based)
* Supports noisy audio
* Works with `.wav` and `.mp3`

### ğŸŒ Multilingual Translation

* Detects spoken language automatically
* Translates to any supported language (English, Tamil, Hindi, etc.)

### ğŸ”Š Text-to-Speech (TTS)

* Converts the assistant's response into audio
* Plays back output instantly

### ğŸ›ï¸ Streamlit Interface (Optional)

* Simple UI to upload audio
* View transcription and translation
* Play generated voice

### ğŸ§ª Test Scripts Included

* Run sample audio files
* Validate Whisper installation
* Debug environment

---

# ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone <your-repo-url>
cd <project-directory>
```

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate     # Windows: .venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

If Whisper fails to install on Windows, run:

```bash
pip install git+https://github.com/openai/whisper.git 
```

---

# ğŸ§  Usage

## â–¶ï¸ Run the Assistant (CLI mode)

```bash
python voice_assistant.py
```

This will:

1. Record/Load audio
2. Transcribe using Whisper
3. Translate text
4. Generate voice output

---

## â–¶ï¸ Run the Streamlit App

```bash
streamlit run app.py
```

Features:

* Upload `.wav` or `.mp3`
* View transcription
* Play voice output
* Select translation language

---

# ğŸ”§ Scripts Overview

### ğŸ“Œ `app.py`

* Streamlit UI
* File upload
* Audio play
* Calls Whisper + TTS pipeline

### ğŸ“Œ `voice_assistant.py`

* Core logic
* Microphone input
* Whisper inference
* Translation + TTS

### ğŸ“Œ `whis.py`

* Encapsulates Whisper model
* STT utilities

### ğŸ“Œ `warn.py`

* Custom warning and notification messages

### ğŸ“Œ `test.py`

* Tests environment + verifies Whisper model

---

# ğŸ”Š Example Command-Line Output

```
[Listening...]
â†’ Detected language: en  
â†’ Transcription: "Hello, how are you?"  
â†’ Translation (Tamil): "à®µà®£à®•à¯à®•à®®à¯, à®à®ªà¯à®ªà®Ÿà®¿ à®‡à®°à¯à®•à¯à®•à®¿à®±à¯€à®°à¯à®•à®³à¯?"  
â†’ Generating voice response...  
[Playing audio]
```

---

# ğŸ§ª Testing the Environment

Run:

```bash
python test_env.py
```

Checks installed packages and Whisper availability.

---

# ğŸ³ Dev Container Support

The `.devcontainer/` folder lets you run the project in:

* GitHub Codespaces
* VS Code Dev Container

With automatic installation of:

* FFmpeg
* Whisper
* Torch
* TTS models

---

# ğŸ¤ Contributing

Feel free to open:

* Issues
* Feature requests
* Pull requests

---

Would you like the **advanced README** version?
